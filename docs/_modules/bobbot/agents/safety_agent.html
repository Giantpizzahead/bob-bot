<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>bobbot.agents.safety_agent &mdash; Bob Bot  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../../_static/documentation_options.js?v=5929fcd5"></script>
        <script src="../../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            Bob Bot
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../bobbot.html">Bob Bot</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../activities.html">Activities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../chess.html">Chess</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../agents.html">Agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../discord_helpers.html">Discord Helpers</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Bob Bot</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">bobbot.agents.safety_agent</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for bobbot.agents.safety_agent</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Agent that checks if a message is appropriate for OpenAI&#39;s models or not.&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span>

<span class="kn">from</span> <span class="nn">langchain_core.messages</span> <span class="kn">import</span> <span class="n">HumanMessage</span><span class="p">,</span> <span class="n">SystemMessage</span>

<span class="kn">from</span> <span class="nn">bobbot.agents.llms</span> <span class="kn">import</span> <span class="n">llm_gpt4omini_factual</span><span class="p">,</span> <span class="n">openai_client</span>
<span class="kn">from</span> <span class="nn">bobbot.utils</span> <span class="kn">import</span> <span class="n">get_logger</span><span class="p">,</span> <span class="n">log_debug_info</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">get_logger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="check_openai_safety">
<a class="viewcode-back" href="../../../agents.html#bobbot.agents.check_openai_safety">[docs]</a>
<span class="k">async</span> <span class="k">def</span> <span class="nf">check_openai_safety</span><span class="p">(</span><span class="n">msg_history</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Determine whether the message history would be handled well by OpenAI&#39;s models.</span>

<span class="sd">    Uses OpenAI&#39;s moderation API and an LLM.</span>
<span class="sd">    Messages containing self-harm related content should be treated seriously.</span>
<span class="sd">    Serious threats toward a person or group of people should also be treated seriously.</span>
<span class="sd">    However, other NSFW messages should not be censored, and therefore should not be handled by OpenAI.</span>

<span class="sd">    Args:</span>
<span class="sd">        msg_history: The message history to check.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Whether OpenAI&#39;s models would handle these messages well.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Preliminary check with OpenAI&#39;s moderation API</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">openai_client</span><span class="o">.</span><span class="n">moderations</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">msg_history</span><span class="p">)</span>
    <span class="n">categories</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">categories</span>  <span class="c1"># https://platform.openai.com/docs/api-reference/moderations/object</span>
    <span class="n">true_categories</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">category</span> <span class="k">for</span> <span class="n">category</span><span class="p">,</span> <span class="n">is_true</span> <span class="ow">in</span> <span class="nb">vars</span><span class="p">(</span><span class="n">categories</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">is_true</span><span class="p">]</span>
    <span class="n">log_debug_info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;===== Safety agent moderations =====</span><span class="se">\n</span><span class="s2">Flagged: </span><span class="si">{</span><span class="n">true_categories</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span>
        <span class="n">categories</span><span class="o">.</span><span class="n">self_harm</span>
        <span class="ow">or</span> <span class="n">categories</span><span class="o">.</span><span class="n">self_harm_instructions</span>
        <span class="ow">or</span> <span class="n">categories</span><span class="o">.</span><span class="n">self_harm_intent</span>
        <span class="ow">or</span> <span class="n">categories</span><span class="o">.</span><span class="n">hate_threatening</span>
        <span class="ow">or</span> <span class="n">categories</span><span class="o">.</span><span class="n">harassment_threatening</span>
        <span class="ow">or</span> <span class="n">categories</span><span class="o">.</span><span class="n">violence</span>
        <span class="ow">or</span> <span class="n">categories</span><span class="o">.</span><span class="n">violence_graphic</span>
    <span class="p">):</span>
        <span class="k">return</span> <span class="kc">True</span>  <span class="c1"># Handle these seriously</span>
    <span class="k">elif</span> <span class="n">categories</span><span class="o">.</span><span class="n">sexual</span> <span class="ow">or</span> <span class="n">categories</span><span class="o">.</span><span class="n">hate</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>  <span class="c1"># Don&#39;t handle these</span>

    <span class="c1"># Precise check with LLM (to find cases like cheating on an exam)</span>
    <span class="n">SAFETY_PROMPT</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;You are an expert decision maker named Bob chatting in a private Discord server. In this server, being toxic, edgy, using profanity, suggestive jokes, etc. is all acceptable. Your goal is to evaluate whether the most recent message in the chat history is appropriate.</span>

<span class="s2">1. For messages that are appropriate, respond with &quot;ACCEPT&quot;. Most messages should be accepted.</span>
<span class="s2">2. For messages that are inappropriate, immoral, or violate ethical standards, respond with &quot;REJECT&quot;.</span>
<span class="s2">3. For messages in a gray area, respond with &quot;GRAY&quot;.</span>

<span class="s2">Here is the server&#39;s message history, including the most recent message. You MUST follow the response format of &#39;Thoughts:&#39;, followed by brainstorming thoughts, then &#39;Answer:&#39;, followed by the answer as one of ACCEPT, REJECT, or GRAY. Keep thoughts very concise.&quot;&quot;&quot;</span>  <span class="c1"># noqa: E501&quot;&quot;&quot;</span>

    <span class="n">messages</span> <span class="o">=</span> <span class="p">[</span><span class="n">SystemMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">SAFETY_PROMPT</span><span class="p">),</span> <span class="n">HumanMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">msg_history</span><span class="p">)]</span>

    <span class="c1"># log_debug_info(f&quot;===== Safety agent history =====\n{messages[1].content}&quot;)</span>
    <span class="n">response</span> <span class="o">=</span> <span class="k">await</span> <span class="n">llm_gpt4omini_factual</span><span class="o">.</span><span class="n">ainvoke</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>
    <span class="n">content</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">content</span>
    <span class="n">log_debug_info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;===== Safety agent LLM response =====</span><span class="se">\n</span><span class="si">{</span><span class="n">content</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1"># Get the decision</span>
    <span class="k">if</span> <span class="s2">&quot;ACCEPT&quot;</span> <span class="ow">in</span> <span class="n">content</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">elif</span> <span class="s2">&quot;GRAY&quot;</span> <span class="ow">in</span> <span class="n">content</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">elif</span> <span class="s2">&quot;REJECT&quot;</span> <span class="ow">in</span> <span class="n">content</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Decision agent did not output a valid response - defaulting to REJECT.&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="kc">True</span></div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Giantpizzahead.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>